{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "81834325",
      "metadata": {
        "id": "81834325"
      },
      "source": [
        "# Writing Efficient Code and GPU Computing Homework\n",
        "\n",
        "Please save your solutions as a **PDF** and upload it to Canvas.\n",
        "\n",
        "## Problem 1: Profiling and Vectorization\n",
        "\n",
        "**(a)** Consider the following cProfile output from a data analysis program:\n",
        "\n",
        "```\n",
        "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
        "     5000    8.234    0.002    8.234    0.002 analysis.py:12(compute_distances)\n",
        "     5000    0.089    0.000    0.089    0.000 analysis.py:28(normalize_vector)\n",
        "  2500000    1.456    0.000    1.456    0.000 analysis.py:35(squared_diff)\n",
        "        1    0.002    0.002    9.781    9.781 analysis.py:50(main)\n",
        "```\n",
        "\n",
        "Which function should you optimize first? Explain your reasoning based on the profiling data. What percentage of the total runtime does this function account for?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6594119a",
      "metadata": {
        "id": "6594119a"
      },
      "source": [
        "`compute_distances` should be optimized first.\n",
        "It has the highest `tottime` (8.234 s), taking up 84% of the total runtime (9.781 s)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce9fb6b5",
      "metadata": {
        "id": "ce9fb6b5"
      },
      "source": [
        "\n",
        "**(b)** The following function computes weighted squared differences between two arrays:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b6ed3c6",
      "metadata": {
        "id": "9b6ed3c6"
      },
      "outputs": [],
      "source": [
        "def weighted_squared_diff_loop(x, y, w):\n",
        "    \"\"\"Compute sum of weighted squared differences using a loop.\"\"\"\n",
        "    n = len(x)\n",
        "    total = 0.0\n",
        "    for i in range(n):\n",
        "        diff = x[i] - y[i]\n",
        "        total += w[i] * diff * diff\n",
        "    return total"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab089216",
      "metadata": {
        "id": "ab089216"
      },
      "source": [
        "Write a vectorized version of this function using NumPy operations. Your function should produce the same result but without explicit Python loops. For example, `weighted_squared_diff(np.array([1, 2, 3]), np.array([0, 1, 1]), np.array([1, 2, 3]))` should return `15.0`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92ad271e",
      "metadata": {
        "id": "92ad271e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def weighted_squared_diff(x, y, w):\n",
        "    \"\"\"Compute sum of weighted squared differences using vectorization.\"\"\"\n",
        "    diff = x - y\n",
        "    return np.sum(w * diff * diff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1828c726",
      "metadata": {
        "id": "1828c726",
        "outputId": "9b513c6c-5a7a-4e76-ffdf-f56e243a535c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weighted_squared_diff(np.array([1, 2, 3]), np.array([0, 1, 1]), np.array([1, 2, 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcab2788",
      "metadata": {
        "id": "bcab2788"
      },
      "source": [
        "**(c)** Write a function that transforms an array by replacing negative values with zero and scaling all positive values by their mean. For example, given `np.array([-2, 4, -1, 6, 2])`, the positive values are `[4, 6, 2]` with mean `4.0`, so the result should be `np.array([0, 1, 0, 1.5, 0.5])`. Use boolean indexing instead of loops."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ebb0c6c",
      "metadata": {
        "id": "7ebb0c6c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def transform_array(arr):\n",
        "    \"\"\"Replace negatives with 0, scale positives by their mean.\"\"\"\n",
        "    arr[arr < 0] = 0\n",
        "    mean_val = np.mean(arr[arr > 0]) if np.any(arr > 0) else 1\n",
        "    arr = arr / mean_val\n",
        "    return arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d8645bd",
      "metadata": {
        "id": "1d8645bd",
        "outputId": "44e49581-ab3a-4751-952e-38cf5099b852"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0. , 1. , 0. , 1.5, 0.5])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transform_array(np.array([-2, 4, -1, 6, 2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b201f5e",
      "metadata": {
        "id": "6b201f5e"
      },
      "source": [
        "## Problem 2: Parallelization and JIT Compilation\n",
        "\n",
        "**(a)** The following function computes the mean of a bootstrap sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc3d71e0",
      "metadata": {
        "id": "dc3d71e0"
      },
      "outputs": [],
      "source": [
        "def compute_bootstrap_mean(args):\n",
        "    \"\"\"Compute mean of a bootstrap sample.\"\"\"\n",
        "    data, seed = args\n",
        "    rng = np.random.RandomState(seed)\n",
        "    sample = rng.choice(data, size=len(data), replace=True)\n",
        "    return np.mean(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f42e9db7",
      "metadata": {
        "id": "f42e9db7"
      },
      "source": [
        "Write a function that uses `multiprocessing.Pool` to compute `n_bootstrap` bootstrap means in parallel. Each bootstrap iteration should receive a unique seed to ensure different random samples. Return a list of the bootstrap means."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74f00419",
      "metadata": {
        "id": "74f00419"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import multiprocessing as mp\n",
        "\n",
        "\n",
        "def compute_bootstrap_mean(args):\n",
        "    \"\"\"Compute mean of a bootstrap sample.\"\"\"\n",
        "    data, seed = args\n",
        "    rng = np.random.RandomState(seed)\n",
        "    sample = rng.choice(data, size=len(data), replace=True)\n",
        "    return np.mean(sample)\n",
        "\n",
        "\n",
        "def parallel_bootstrap(data, n_bootstrap, n_workers=4, base_seed=None):\n",
        "    \"\"\"Compute bootstrap means in parallel.\"\"\"\n",
        "    # Deterministic seeds when base_seed is provided\n",
        "    if base_seed is not None:\n",
        "        seed_rng = np.random.RandomState(base_seed)\n",
        "        seeds = seed_rng.randint(0, 2**32, size=n_bootstrap)\n",
        "    else:\n",
        "        seeds = np.random.randint(0, 2**32, size=n_bootstrap)\n",
        "\n",
        "    args_list = [(data, int(seed)) for seed in seeds]\n",
        "    with mp.Pool(processes=n_workers) as pool:\n",
        "        means = pool.map(compute_bootstrap_mean, args_list)\n",
        "    return means"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "883234d6",
      "metadata": {
        "id": "883234d6"
      },
      "source": [
        "**(b)** Write a Numba-optimized function that computes the running maximum of an array. For each position `i`, the output should contain the maximum of all elements from index 0 to `i` (inclusive). For example, `running_max(np.array([3, 1, 4, 1, 5, 9, 2, 6]))` should return `np.array([3, 3, 4, 4, 5, 9, 9, 9])`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce3f9fd4",
      "metadata": {
        "id": "ce3f9fd4"
      },
      "outputs": [],
      "source": [
        "from numba import njit\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "@njit\n",
        "def running_max(arr):\n",
        "    \"\"\"Compute running maximum of array.\"\"\"\n",
        "    n = arr.size\n",
        "    out = np.empty_like(arr)\n",
        "\n",
        "    current = arr[0]\n",
        "    out[0] = current\n",
        "    for i in range(1, n):\n",
        "        val = arr[i]\n",
        "        if val > current:\n",
        "            current = val\n",
        "        out[i] = current\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75eb8e99",
      "metadata": {
        "id": "75eb8e99",
        "outputId": "ca874899-ea66-4b60-9655-62c616edf258"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 3, 4, 4, 5, 9, 9, 9])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "running_max(np.array([3, 1, 4, 1, 5, 9, 2, 6]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba135006",
      "metadata": {
        "id": "ba135006"
      },
      "source": [
        "**(c)** The following Numba function attempts to filter an array to keep only positive values, but it fails to compile. Explain why it fails and provide a corrected version that compiles successfully with `@njit`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83e89816",
      "metadata": {
        "id": "83e89816",
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "from numba import njit\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "@njit\n",
        "def filter_positive_broken(arr):\n",
        "    \"\"\"Return array containing only positive values (BROKEN).\"\"\"\n",
        "    result = []\n",
        "    for x in arr:\n",
        "        if x > 0:\n",
        "            result.append(x)\n",
        "    return np.array(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "604782b2",
      "metadata": {
        "id": "604782b2"
      },
      "source": [
        "For older Numba versions, this function fails to compile. This is because a Python list has unknown element type (`result = []`), and the types of the new elements cannot be inferred (`result.append(x)`). Nopython mode requires these to be known at compile time.\n",
        "\n",
        "For newer Numba versions, this function compiles successfully. This is because typed lists (list with one fixed element type) become supported. The element type can be inferred from the first appended value."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94f21d7f",
      "metadata": {
        "id": "94f21d7f"
      },
      "source": [
        "## Problem 3: GPU Computing Fundamentals\n",
        "\n",
        "**(a)** For each of the following computational tasks, state whether it would benefit from GPU acceleration and explain why or why not.\n",
        "\n",
        "1. Computing the mean of 500 numbers\n",
        "\n",
        "**No**. The data is too small. The overhead of data transfer exceeds the time saved through computation.\n",
        "\n",
        "2. Multiplying two 5000x5000 matrices\n",
        "\n",
        "**Yes**. Large matrix operation can be sped up by GPU computing, since it's highly parallelizable.\n",
        "\n",
        "3. Reading a 10GB CSV file from disk\n",
        "\n",
        "**No**. GPU accelartion is not beneficial for I/O-bound tasks.\n",
        "\n",
        "4. Running 1 million independent Monte Carlo simulations\n",
        "\n",
        "**Yes**. The number of trials is huge; the trials are independent; each trial is simple numeric work.\n",
        "\n",
        "5. Computing Fibonacci numbers recursively\n",
        "\n",
        "**No**. The iterations are not independent. This task is sequential."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a358206",
      "metadata": {
        "id": "1a358206"
      },
      "source": [
        "**(b)** The following code runs slowly despite using GPU. Identify the performance problem and rewrite the code to fix it. The goal is to compute the sum of squares for 1000 different arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bef6c717",
      "metadata": {
        "id": "bef6c717",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd47eb58-e518-45db-fe15-80b60e23dfb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total: 9998343.54916972\n"
          ]
        }
      ],
      "source": [
        "import cupy as cp\n",
        "import numpy as np\n",
        "\n",
        "results = []\n",
        "for i in range(1000):\n",
        "    data = np.random.randn(10000)  # Generate on CPU\n",
        "    gpu_data = cp.asarray(data)    # Transfer to GPU\n",
        "    result = cp.sum(gpu_data ** 2) # Compute on GPU\n",
        "    results.append(result.get())   # Transfer back to CPU\n",
        "\n",
        "print(f\"Total: {sum(results)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ae78333",
      "metadata": {
        "id": "5ae78333"
      },
      "source": [
        "Write an efficient version that minimizes data transfers between CPU and GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is transferred to the GPU 1000 times, which is time-consuming, since data transfer between CPU and GPU is slow comparing to computation.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "697WrqkWSO46"
      },
      "id": "697WrqkWSO46"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6318197d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "251abb9f-74b9-40f5-830d-627e6a71ab68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total: 9999450.239834026\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "\n",
        "data = np.random.randn(1000, 10000)\n",
        "gpu_data = cp.asarray(data)\n",
        "results_cp = cp.sum(gpu_data ** 2, axis = 1)\n",
        "results = results_cp.get()\n",
        "\n",
        "print(f\"Total: {sum(results)}\")\n"
      ],
      "id": "6318197d"
    },
    {
      "cell_type": "markdown",
      "id": "7265175a",
      "metadata": {
        "id": "7265175a"
      },
      "source": [
        "## Problem 4: CuPy and PyTorch\n",
        "\n",
        "**(a)** Convert the following NumPy code to CuPy. The function computes z-score normalization and then the correlation matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "86981b8b",
      "metadata": {
        "id": "86981b8b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def correlation_matrix_numpy(X):\n",
        "    \"\"\"Compute correlation matrix after z-score normalization.\n",
        "\n",
        "    X has shape (n_samples, n_features).\n",
        "    \"\"\"\n",
        "    # Z-score normalize each column\n",
        "    mean = np.mean(X, axis=0)\n",
        "    std = np.std(X, axis=0)\n",
        "    Z = (X - mean) / std\n",
        "\n",
        "    # Compute correlation matrix\n",
        "    n = X.shape[0]\n",
        "    corr = (Z.T @ Z) / n\n",
        "    return corr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f725bb1e",
      "metadata": {
        "id": "f725bb1e"
      },
      "source": [
        "Write the CuPy version that performs the computation on GPU and returns the result as a NumPy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cad7c938",
      "metadata": {
        "id": "cad7c938"
      },
      "outputs": [],
      "source": [
        "import cupy as cp\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def correlation_matrix_cupy(X):\n",
        "    \"\"\"Compute correlation matrix using CuPy (GPU).\"\"\"\n",
        "    X_cp = cp.asarray(X)\n",
        "    mean_cp = cp.mean(X_cp, axis=0)\n",
        "    std_cp = cp.std(X_cp, axis=0)\n",
        "    Z_cp = (X_cp - mean_cp) / std_cp\n",
        "\n",
        "    n = X.shape[0]\n",
        "    corr_cp = (Z_cp.T @ Z_cp) / n\n",
        "\n",
        "    return corr_cp.get()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe047ad6",
      "metadata": {
        "id": "fe047ad6"
      },
      "source": [
        "**(b)** The following PyTorch code has a bug that causes a runtime error. Identify the error and provide the corrected code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "6fd55abb",
      "metadata": {
        "id": "6fd55abb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def process_data(numpy_array):\n",
        "    \"\"\"Process data using PyTorch on GPU.\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Convert to tensor and move to GPU\n",
        "    x = torch.from_numpy(numpy_array).to(device)\n",
        "\n",
        "    # Create another tensor for computation\n",
        "    weights = torch.ones(len(numpy_array))\n",
        "\n",
        "    # Weighted sum\n",
        "    result = torch.sum(x * weights)\n",
        "\n",
        "    return result.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All tensors are expected to be on the same device. While `x` is on the GPU, `weights` is on the CPU."
      ],
      "metadata": {
        "id": "uCl_G2na077d"
      },
      "id": "uCl_G2na077d"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def process_data(numpy_array):\n",
        "    \"\"\"Process data using PyTorch on GPU.\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Convert to tensor and move to GPU\n",
        "    x = torch.from_numpy(numpy_array).to(device)\n",
        "\n",
        "    # Create another tensor for computation\n",
        "    weights = torch.ones(len(numpy_array)).to(device)\n",
        "\n",
        "    # Weighted sum\n",
        "    result = torch.sum(x * weights)\n",
        "\n",
        "    return result.item()"
      ],
      "metadata": {
        "id": "siidS6ZrzE9o"
      },
      "id": "siidS6ZrzE9o",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "870e56d4",
      "metadata": {
        "id": "870e56d4"
      },
      "source": [
        "**(c)** Explain why the following GPU timing code gives incorrect measurements. Then provide corrected code that accurately measures GPU computation time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bcdf793",
      "metadata": {
        "id": "4bcdf793",
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "device = torch.device('cuda')\n",
        "a = torch.randn(5000, 5000, device=device)\n",
        "b = torch.randn(5000, 5000, device=device)\n",
        "\n",
        "start = time.perf_counter()\n",
        "c = torch.mm(a, b)\n",
        "elapsed = time.perf_counter() - start\n",
        "print(f\"Time: {elapsed*1000:.2f} ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yUaBKkDI1xGP"
      },
      "id": "yUaBKkDI1xGP"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5MwZMY_p1xe-"
      },
      "id": "5MwZMY_p1xe-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bb007cff",
      "metadata": {
        "id": "bb007cff"
      },
      "source": [
        "## Problem 5: Performance Comparison\n",
        "\n",
        "**(a)** In extreme value statistics, we often need to estimate the probability that the maximum of n independent standard normal random variables exceeds a threshold t. This can be done via Monte Carlo simulation: generate n normal values, take the maximum, and check if it exceeds t. Repeat this many times and compute the proportion that exceed t.\n",
        "\n",
        "Implement two versions of this simulation:\n",
        "\n",
        "1. A Numba-optimized CPU version using `@njit`\n",
        "2. A CuPy GPU version using vectorized operations\n",
        "\n",
        "Both functions should take parameters `n` (number of normal values per trial), `t` (threshold), and `n_simulations` (number of Monte Carlo trials), and return the estimated probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "518b5f29",
      "metadata": {
        "id": "518b5f29"
      },
      "outputs": [],
      "source": [
        "from numba import njit\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "\n",
        "\n",
        "@njit\n",
        "def estimate_prob_numba(n, t, n_simulations):\n",
        "    \"\"\"Estimate P(max of n normals > t) using Numba.\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "def estimate_prob_cupy(n, t, n_simulations):\n",
        "    \"\"\"Estimate P(max of n normals > t) using CuPy.\"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59b134e3",
      "metadata": {
        "id": "59b134e3"
      },
      "source": [
        "**(b)** Design an experiment to find the \"crossover point\" where the GPU version becomes faster than the CPU version. Your experiment should vary the problem size (e.g., `n_simulations`) and measure execution time for both implementations. Describe what factors affect where this crossover occurs and what values you would test.\n",
        "\n",
        "**(c)** Suppose you need to run a very large simulation with `n_simulations = 100_000_000` but your GPU only has 8GB of memory. The naive CuPy implementation would require generating a matrix of shape `(n_simulations, n)` which may not fit in memory. Write a batched version that processes the simulations in chunks to stay within memory limits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f51590a",
      "metadata": {
        "id": "3f51590a"
      },
      "outputs": [],
      "source": [
        "import cupy as cp\n",
        "\n",
        "\n",
        "def estimate_prob_cupy_batched(n, t, n_simulations, batch_size=1_000_000):\n",
        "    \"\"\"Estimate P(max of n normals > t) using CuPy with batching.\"\"\"\n",
        "    pass"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}